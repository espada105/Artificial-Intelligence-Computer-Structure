{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1wtWbMBDna6grAptQWGydTIQENGVIql2B",
      "authorship_tag": "ABX9TyMtlQyVxXiT6RMCqEvQhNCj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/espada105/Artificial-Intelligence-Computer-Structure/blob/main/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5_%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B5%AC%EC%A1%B0_5%EC%A3%BC%EC%B0%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXj2scOkvz0j",
        "outputId": "e40dfc57-bfc4-48ac-a359-30926a2177d5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The nvcc4jupyter extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc4jupyter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hO5qpmuvtOe",
        "outputId": "ba324fc9-ff96-45be-ea9f-2e57a7d96c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JQPK5oHlJrsE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86aea949-0b08-4ef5-e078-bd9d02064e34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Oct  7 02:15:47 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "\n",
        "#gpu 드라이버, tesla t4 글카이름, gpu v램  size: 15360MB,"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#nvcc는 컴파일러 sm_70은 아키텍처이름, cpu_gpu를 컴파일하고난 이름이 cpu_gpu,\n",
        "# gpu에서 쓰기 위해 __global__사용\n",
        "!nvcc -arch=sm_70 -o cpu_gpu.cu ./cpu_gpu.cu -run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaCGvov-ru4D",
        "outputId": "49569224-e9ab-4aa6-bf53-64a4b943038b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This function is defined to run on the CPU.\n",
            "This function is defined to run on the GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "void CPUFunction(){\n",
        "    printf(\"This function is defined to run on the CPU. \\n\");\n",
        "}\n",
        "\n",
        "__global__ void GPUFunction(){\n",
        "    printf(\"This function is defined to run on the GPU. \\n\");\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    CPUFunction();\n",
        "    GPUFunction<<<1, 1>>>();\n",
        "\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfnLrKxrs3t7",
        "outputId": "f95d5e50-cca1-4523-a7ad-6e357d10ed39"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This function is defined to run on the CPU. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_70 -o cpu_gpu_2.cu ./cpu_gpu_2.cu -run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnzdIh6e04QZ",
        "outputId": "01a1fca7-2f61-4bf2-f2cf-e9bf71a3f066"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "병렬로 실행중입니다. \n",
            "병렬로 실행중입니다. \n",
            "병렬로 실행중입니다. \n",
            "병렬로 실행중입니다. \n",
            "병렬로 실행중입니다. \n",
            "병렬로 실행중입니다. \n",
            "병렬로 실행중입니다. \n",
            "병렬로 실행중입니다. \n",
            "병렬로 실행중입니다. \n",
            "병렬로 실행중입니다. \n",
            "병렬로 실행중입니다. \n",
            "병렬로 실행중입니다. \n",
            "병렬로 실행중입니다. \n",
            "병렬로 실행중입니다. \n",
            "병렬로 실행중입니다. \n",
            "병렬로 실행중입니다. \n",
            "병렬로 실행중입니다. \n",
            "병렬로 실행중입니다. \n",
            "병렬로 실행중입니다. \n",
            "병렬로 실행중입니다. \n",
            "병렬로 실행중입니다. \n",
            "병렬로 실행중입니다. \n",
            "병렬로 실행중입니다. \n",
            "병렬로 실행중입니다. \n",
            "병렬로 실행중입니다. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_70 -o cpu_gpu_3.cu ./cpu_gpu_3.cu -run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_BNANtI3L9V",
        "outputId": "96d930d9-8e1c-4c0e-b778-640d12a3f31e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 스레드 실행 성공!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_70 -o cpu_gpu_4.cu ./cpu_gpu_4.cu -run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXcQCERb9Axw",
        "outputId": "93e7d5d6-a38b-438e-c238-7d98c4ca36c1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "반복횟수 0\n",
            "반복횟수 1\n",
            "반복횟수 2\n",
            "반복횟수 3\n",
            "반복횟수 4\n",
            "반복횟수 5\n",
            "반복횟수 6\n",
            "반복횟수 7\n",
            "반복횟수 8\n",
            "반복횟수 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_70 -o cpu_gpu_5.cu ./cpu_gpu_5.cu -run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49Hu8-7BAa-S",
        "outputId": "8ac6d432-a6a2-4f59-fbdd-3fa427c5fc98"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모든 배열 원소에 2를 곱한 결과가 들어갔나요? 네\n"
          ]
        }
      ]
    }
  ]
}